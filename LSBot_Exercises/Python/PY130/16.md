# PY130
## Problem 16: Decorator Order and Execution

Consider the following two decorators and a function:

```python
from time import perf_counter
from functools import lru_cache

def time_runs(func):
    def wrapper(*args, **kwargs):
        start = perf_counter()
        return_value = func(*args, **kwargs)
        print(f"The function ran in {perf_counter()-start} seconds")
        return return_value
    return wrapper

@time_runs
@lru_cache
def is_prime(n):
    for i in range(2, n):
        if (n % i) == 0:
            return False
    return True
```

Explain the order in which the decorators are applied during the function's definition and during its execution. What would be the difference in behavior if the order of the decorators was swapped?

<details>
<summary>Solution:</summary>

Decorators are applied **bottom-up** (from the function outward):

```python
@time_runs      # Applied second (outer)
@lru_cache      # Applied first (inner)
def is_prime(n):
    # original function
```

This is equivalent to:
```python
is_prime = time_runs(lru_cache(is_prime))
```

**Execution Flow with Current Order:**

1. `lru_cache` is applied first, creating a cached version of `is_prime`
2. `time_runs` wraps the cached version
3. When called:
   - `time_runs` wrapper starts timing
   - Calls the cached version of `is_prime`
   - If result is cached, returns immediately (very fast)
   - If not cached, runs original function and caches result
   - `time_runs` reports the time (including cache lookup)

**Example Output:**
```python
print(is_prime(97))    # First call - runs actual computation
# The function ran in 0.0001234 seconds
# True

print(is_prime(97))    # Second call - uses cache
# The function ran in 0.0000012 seconds  # Much faster!
# True
```

**If Order Was Swapped (@lru_cache on top, @time_runs below):**

```python
@lru_cache      # Applied second (outer)
@time_runs      # Applied first (inner)
def is_prime(n):
    # original function
```

Equivalent to: `is_prime = lru_cache(time_runs(is_prime))`

**Different Behavior:**
- `time_runs` would wrap the original function first
- `lru_cache` would cache the **timed wrapper function**
- **Problem**: The timing print statement would only execute once per unique argument
- Subsequent calls with the same argument would return cached results WITHOUT timing information

**Example with Swapped Order:**
```python
print(is_prime(97))    # First call - runs computation with timing
# The function ran in 0.0001234 seconds
# True

print(is_prime(97))    # Second call - returns cached result, NO timing output
# True  (no timing message!)
```

**Key Insight:** The order matters significantly! The current order (`@time_runs` then `@lru_cache`) allows you to measure both cached and uncached performance, while the swapped order would hide timing information for cached calls.

</details>

---

[Previous](15.md) | [Next](17.md)